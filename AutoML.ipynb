{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of AutoML.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/leobezerra/automl-pybr14/blob/master/AutoML.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "e15U-L9UNTJ1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# AutoML with Python\n",
        "\n",
        "In this notebook, we'll create a classifier for a digit classification problem in an automated way.\n",
        "\n",
        "We'll use the ```auto-sklearn``` package for that, which implements the AutoSklean approach to AutoML.\n",
        "\n",
        "AutoSklearn is approach based on ensembles that is able to select and configure algorithms in an automated way.\n",
        "\n",
        "It takes as input a labeled training set and produces an algorithm expected to perform well on that input problem.\n",
        "\n",
        "AutoSklearn can be used both for classification and regression.\n",
        "\n",
        "In this example, we'll create a classifier for the MNIST handwritten digit classification problem. "
      ]
    },
    {
      "metadata": {
        "id": "e_Eohh2bOc_e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Installing auto-sklearn"
      ]
    },
    {
      "metadata": {
        "id": "FM1i581_OhYL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```auto-sklearn``` package has a few dependencies we need to install first:"
      ]
    },
    {
      "metadata": {
        "id": "TYW9fd8lSkLq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note que o comando abaixo funciona no Colab e em distribuições Linux baseadas em Debian. Se você usa outra plataforma, você precisará instalar essa biblioteca manualmente.**"
      ]
    },
    {
      "metadata": {
        "id": "hE7eqiD3322e",
        "colab_type": "code",
        "outputId": "50f4d44e-ea1e-4088-8db7-d0b6c243adc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install build-essential swig"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 12 not upgraded.\n",
            "Need to get 1,100 kB of archives.\n",
            "After this operation, 5,822 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
            "Fetched 1,100 kB in 1s (1,297 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 22278 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.12-1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
            "Unpacking swig (3.0.12-1) ...\n",
            "Setting up swig3.0 (3.0.12-1) ...\n",
            "Setting up swig (3.0.12-1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7ZT30xys21YS",
        "colab_type": "code",
        "outputId": "17b1eae7-caa2-4d99-fc40-423a09a34f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2468
        }
      },
      "cell_type": "code",
      "source": [
        "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   209  100   209    0     0   1514      0 --:--:-- --:--:-- --:--:--  1514\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (40.4.3)\n",
            "Collecting nose\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
            "\u001b[K    100% |████████████████████████████████| 163kB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: nose\n",
            "Successfully installed nose-1.3.7\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Collecting Cython\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/3f/cac281f3f019b825bbc03fa8cb7eb03d9c355f4aa9eef978279a4966cb21/Cython-0.29-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 2.1MB 9.4MB/s \n",
            "\u001b[?25hInstalling collected packages: Cython\n",
            "Successfully installed Cython-0.29\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.14.1) (1.14.6)\n",
            "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (0.19.2)\n",
            "Collecting xgboost==0.7.post3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/1c/a2ec1798d444e2b86b27fdbf18d9ab08c25c3d374de77429b55a76f42404/xgboost-0.7.post3.tar.gz (450kB)\n",
            "\u001b[K    100% |████████████████████████████████| 460kB 5.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost==0.7.post3) (1.14.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost==0.7.post3) (0.19.1)\n",
            "Building wheels for collected packages: xgboost\n",
            "  Running setup.py bdist_wheel for xgboost ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/94/02/70/61da39c3c6e67d052eb5c618c2b5188adcd6ab0128025f1323\n",
            "Successfully built xgboost\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 0.7.post4\n",
            "    Uninstalling xgboost-0.7.post4:\n",
            "      Successfully uninstalled xgboost-0.7.post4\n",
            "Successfully installed xgboost-0.7.post3\n",
            "Collecting lockfile\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n",
            "Installing collected packages: lockfile\n",
            "Successfully installed lockfile-0.12.2\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.12.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
            "Collecting liac-arff\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/c3/6966861e2f4d302ac3a36821f7ac503b57d98cb9cc3b28e9cd8ef8b7df65/liac-arff-2.3.1.tar.gz\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Running setup.py bdist_wheel for liac-arff ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/f0/15/97687f0a23a6859a7ced7e09271d321930c6641c2675d04745\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.3.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
            "Collecting ConfigSpace<0.5,>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/53/e54835d444153ba461fe8aec28533a1ffc3c5531b89509c8029b6b57a7e7/ConfigSpace-0.4.7.tar.gz (913kB)\n",
            "\u001b[K    100% |████████████████████████████████| 921kB 19.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (1.14.6)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (2.2.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (3.6.6)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (0.29)\n",
            "Building wheels for collected packages: ConfigSpace\n",
            "  Running setup.py bdist_wheel for ConfigSpace ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fb/05/bc/ace7b3602c315c402176a9280296a59275aa826476517faa24\n",
            "Successfully built ConfigSpace\n",
            "Installing collected packages: ConfigSpace\n",
            "Successfully installed ConfigSpace-0.4.7\n",
            "Collecting pynisher>=0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/b2/21/c86c64c305da6d43fb89780d33cbc839c07736b71955a8bdb642a02b7538/pynisher-0.5.0.tar.gz\n",
            "Collecting docutils>=0.3 (from pynisher>=0.4)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4) (40.4.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4) (5.4.7)\n",
            "Building wheels for collected packages: pynisher\n",
            "  Running setup.py bdist_wheel for pynisher ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/af/2a/c4/ec3abc8a2f786ef9786ea8fe6ff629a4e54812a3f98cc41b47\n",
            "Successfully built pynisher\n",
            "Installing collected packages: docutils, pynisher\n",
            "Successfully installed docutils-0.14 pynisher-0.5.0\n",
            "Collecting pyrfr<0.8,>=0.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/c6/c555cfa3c7d0078dded091d4901ed52344bbb925077aa70b871faf35fd58/pyrfr-0.7.4.tar.gz (291kB)\n",
            "\u001b[K    100% |████████████████████████████████| 296kB 4.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyrfr\n",
            "  Running setup.py bdist_wheel for pyrfr ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fb/98/fd/b1d53cab6d5ed836980777d9733d7e549d82a727650eed6f6d\n",
            "Successfully built pyrfr\n",
            "Installing collected packages: pyrfr\n",
            "Successfully installed pyrfr-0.7.4\n",
            "Collecting smac\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ab/2b0a6fb00bd76e2415a04dcca453ad0b0db9b4218b02401306ff2bc6135d/smac-0.8.0.tar.gz (94kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from smac) (40.4.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from smac) (0.29)\n",
            "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from smac) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from smac) (0.19.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac) (1.11.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from smac) (5.4.7)\n",
            "Requirement already satisfied: pynisher>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from smac) (0.5.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.3 in /usr/local/lib/python3.6/dist-packages (from smac) (0.4.7)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from smac) (0.19.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from smac) (3.6.6)\n",
            "Requirement already satisfied: pyrfr>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from smac) (0.7.4)\n",
            "Collecting sphinx (from smac)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e0/e9e83b244eaa382ba21896dda6172617e47aff0be225eb72782cca105d3c/Sphinx-1.8.1-py2.py3-none-any.whl (3.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.1MB 7.3MB/s \n",
            "\u001b[?25hCollecting sphinx_rtd_theme (from smac)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/0c/e4a462190506bc4bff6ca8cf93da07b2d13e540466d2e8a760352d0c69b0/sphinx_rtd_theme-0.4.2-py2.py3-none-any.whl (6.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 6.4MB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from smac) (0.12.5)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.1->smac) (0.14)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.3->smac) (2.2.2)\n",
            "Collecting imagesize (from sphinx->smac)\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/b6/aef66b4c52a6ad6ac18cf6ebc5731ed06d8c9ae4d3b2d9951f261150be67/imagesize-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.18.4)\n",
            "Collecting snowballstemmer>=1.1 (from sphinx->smac)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/6c/8a935e2c7b54a37714656d753e4187ee0631988184ed50c0cf6476858566/snowballstemmer-1.2.1-py2.py3-none-any.whl (64kB)\n",
            "\u001b[K    100% |████████████████████████████████| 71kB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.1.3)\n",
            "Collecting alabaster<0.8,>=0.7 (from sphinx->smac)\n",
            "  Downloading https://files.pythonhosted.org/packages/10/ad/00b090d23a222943eb0eda509720a404f531a439e803f6538f35136cae9e/alabaster-0.7.12-py2.py3-none-any.whl\n",
            "Collecting babel!=2.0,>=1.3 (from sphinx->smac)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ad/c6f60602d3ee3d92fbed87675b6fb6a6f9a38c223343ababdb44ba201f10/Babel-2.6.0-py2.py3-none-any.whl (8.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 8.1MB 4.8MB/s \n",
            "\u001b[?25hCollecting sphinxcontrib-websupport (from sphinx->smac)\n",
            "  Downloading https://files.pythonhosted.org/packages/52/69/3c2fbdc3702358c5b34ee25e387b24838597ef099761fc9a42c166796e8f/sphinxcontrib_websupport-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.10)\n",
            "Collecting packaging (from sphinx->smac)\n",
            "  Downloading https://files.pythonhosted.org/packages/89/d1/92e6df2e503a69df9faab187c684585f0136662c12bb1f36901d426f3fab/packaging-18.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (2018.10.15)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (2.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (3.0.4)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx->smac) (2018.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac) (1.0)\n",
            "Building wheels for collected packages: smac\n",
            "  Running setup.py bdist_wheel for smac ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/12/52/83/d2d66a840968025d072ddb1cd776fdc5eb5e337e1cc887bc3f\n",
            "Successfully built smac\n",
            "Installing collected packages: imagesize, snowballstemmer, alabaster, babel, sphinxcontrib-websupport, packaging, sphinx, sphinx-rtd-theme, smac\n",
            "Successfully installed alabaster-0.7.12 babel-2.6.0 imagesize-1.1.0 packaging-18.0 smac-0.8.0 snowballstemmer-1.2.1 sphinx-1.8.1 sphinx-rtd-theme-0.4.2 sphinxcontrib-websupport-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4VpHBKBGOhUg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Note that pip expects the name ```auto-sklearn``` rather than ```autosklearn```**"
      ]
    },
    {
      "metadata": {
        "id": "oY2e7h5F2ry4",
        "colab_type": "code",
        "outputId": "5d09eeba-97ad-4038-b69a-64691b98e974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install auto-sklearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting auto-sklearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/a6/cbbff9205cb7dc71d67a6c05ecdd5aa05856bc1638360238d25a4a01d670/auto-sklearn-0.4.0.tar.gz (3.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 3.4MB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (40.4.3)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.11.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.1)\n",
            "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.2)\n",
            "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.7)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.3.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.22.0)\n",
            "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.4.7)\n",
            "Collecting pynisher<0.5,>=0.4 (from auto-sklearn)\n",
            "  Downloading https://files.pythonhosted.org/packages/d2/cd/4e0469a55fd280df177af2d5e94d72541d3bb0115280e31a23c8922987e6/pynisher-0.4.2.tar.gz\n",
            "Requirement already satisfied: pyrfr<0.8,>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.4)\n",
            "Requirement already satisfied: smac<0.9,>=0.8 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.8.0)\n",
            "Requirement already satisfied: xgboost==0.7.post3 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.post3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.2.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (3.6.6)\n",
            "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher<0.5,>=0.4->auto-sklearn) (0.14)\n",
            "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac<0.9,>=0.8->auto-sklearn) (1.8.1)\n",
            "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac<0.9,>=0.8->auto-sklearn) (0.4.2)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.1.3)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.18.4)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (0.7.12)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (1.1.0)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.6.0)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (1.2.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (18.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.10)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (1.1.0)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (2018.10.15)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac<0.9,>=0.8->auto-sklearn) (1.0)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher\n",
            "  Running setup.py bdist_wheel for auto-sklearn ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3f/4e/d9/489ca4cb2f6fd94f58180b0073d15746583f772f25d9178b94\n",
            "  Running setup.py bdist_wheel for pynisher ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/35/cb/37fe9c279ac6e56fc8805e146a431c27550dce1ad868ffa04e\n",
            "Successfully built auto-sklearn pynisher\n",
            "Installing collected packages: pynisher, auto-sklearn\n",
            "  Found existing installation: pynisher 0.5.0\n",
            "    Uninstalling pynisher-0.5.0:\n",
            "      Successfully uninstalled pynisher-0.5.0\n",
            "Successfully installed auto-sklearn-0.4.0 pynisher-0.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F82AQt_0Q9kK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "metadata": {
        "id": "KlRSVHzSTMNs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this example, we'll use the classification module of AutoSklearn."
      ]
    },
    {
      "metadata": {
        "id": "gQEOA3r0TJLi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from autosklearn.classification import AutoSklearnClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AW80nPVREcg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll also need the metrics module from scikit-learn when evaluating the model produced. We'll use the accuracy and confusion matrix tools."
      ]
    },
    {
      "metadata": {
        "id": "t1TfvL1K2PCr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wi3AiCGwTigl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Reading the data"
      ]
    },
    {
      "metadata": {
        "id": "QRTDnfy_TRg0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We'll use the MNIST dataset available in TensorFlow.\n",
        "\n",
        "**You can also download this dataset from other sources, if you don't (wanna) have TensorFlow installed in your computer.**\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "2k4rjulgTRXA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHssKO0b42Tp",
        "colab_type": "code",
        "outputId": "6bf194b9-cdeb-470a-981a-e469700d62dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "cell_type": "code",
      "source": [
        "m=input_data.read_data_sets(\"MNIST\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [18:04:29:tensorflow] From <ipython-input-7-d32cef2642e0>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "[WARNING] [18:04:29:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "[WARNING] [18:04:29:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "[WARNING] [18:04:30:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "Extracting MNIST/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [18:04:30:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "[WARNING] [18:04:30:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "huj7FcvTT07d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This dataset comes pre-split into a training and a testing subset. \n",
        "\n",
        "**This is extremely important to ensure that the produced model is good at classifying new samples, not just the ones it already knows.** "
      ]
    },
    {
      "metadata": {
        "id": "rh7WxAnDURry",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training examples"
      ]
    },
    {
      "metadata": {
        "id": "ZMgNQ6-wUiDV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training subset contains two structures: ```images``` and  ```labels```.\n",
        "\n",
        "Let's check what's in ```images```:\n",
        "\n",
        "**The machine learning community has conventioned that X is used for examples and y for labels.** "
      ]
    },
    {
      "metadata": {
        "id": "hEbqD3uW47da",
        "colab_type": "code",
        "outputId": "52406684-1a3f-4eb3-c6ca-604a45cd5179",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "X_train = m.train.images\n",
        "print(\"X_train\")\n",
        "print(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Kmgrh_jU_Hj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "From what we can see, X_train is a matrix with lots of zeros. \n",
        "\n",
        "Let's check a bit more:"
      ]
    },
    {
      "metadata": {
        "id": "KUPo2LUt5XMm",
        "colab_type": "code",
        "outputId": "43658618-e166-43eb-a40e-186566e70b88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(X_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "jTjuNeKPWkRl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you're used to pandas, scikit-learn or other data science / machine learning packages, you've probably come across ```ndarrays``` from the ```numpy``` package.\n",
        "\n",
        "It is basically a more efficient version of a python ```list```, and we can check its dimensions using the attribute ```shape```:"
      ]
    },
    {
      "metadata": {
        "id": "xHJl7kXg5Haz",
        "colab_type": "code",
        "outputId": "3d8e8985-288c-4d18-de74-891d0c81f3f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "2F6klrpCXaOg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The shape of the ```images``` collection reveals that it contains 55000 images, each represented by a 784 array.\n",
        "\n",
        "Each vector is the result of flattening the original 28x28 image (28 * 28 = 784).\n",
        "\n",
        "**This used to be a very common representation in computer vision problems before deep learning algorithms, since flattening an image makes the data compatible with most algorithms but discards the vertical spatial relation between pixels.**"
      ]
    },
    {
      "metadata": {
        "id": "mjAsvMXAYTCs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's check what's in the ```labels``` collection."
      ]
    },
    {
      "metadata": {
        "id": "sH8LF_KX5Bd6",
        "colab_type": "code",
        "outputId": "522176d3-2832-4969-b3fc-e311590bfb43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "y_train = m.train.labels\n",
        "print(\"y_train\")\n",
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train\n",
            "[7 3 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KrinBiaWYZJu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This time we have a one-dimensional array, but what do the values mean?\n",
        "\n",
        "Let's check its type."
      ]
    },
    {
      "metadata": {
        "id": "4cALLzfI5iEz",
        "colab_type": "code",
        "outputId": "21b58b03-df32-4a2b-ea45-460b04aeb1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "dDtZ4QGzY5jc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Again, we have an ```ndarray```,  so we can check its shape:"
      ]
    },
    {
      "metadata": {
        "id": "qBeQN0jh5rCc",
        "colab_type": "code",
        "outputId": "75835743-2f0c-4076-b8ed-d0960a285908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "ZJl8ux4rY-5z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```labels``` collection states to which class each of the 55000 images from the ```images``` collection belongs to.\n",
        "\n",
        "In this case, labels range from 0 to 9, since those are the handwritten digits present in the dataset.\n",
        "\n",
        "**We can do some descriptive analysis of our data using Pandas and plotting libraries. Here I'll keep it simple and check only the distribution of the training examples across the different classes.**"
      ]
    },
    {
      "metadata": {
        "id": "VfP9Gbi8ZeL2",
        "colab_type": "code",
        "outputId": "9662bd70-6db5-4470-981a-1b52a413d0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "from pandas import Series\n",
        "Series(y_train).value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    6179\n",
              "7    5715\n",
              "3    5638\n",
              "2    5470\n",
              "9    5454\n",
              "0    5444\n",
              "6    5417\n",
              "8    5389\n",
              "4    5307\n",
              "5    4987\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "RGOrOSf6Z7EA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that the data set contains many more images of 1 than of 5. \n",
        "\n",
        "**It's possible to preprocess the data to balance the number of examples from each class. I won't do it here to keep the notebook simple, but this is often helpful for the performance of the models.**"
      ]
    },
    {
      "metadata": {
        "id": "otcqEQZTaUda",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing examples"
      ]
    },
    {
      "metadata": {
        "id": "LvwtbsIZahwM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's check what the testing subset looks like. Again, it contains collections of ```images``` and ```labels```."
      ]
    },
    {
      "metadata": {
        "id": "N1t3Cvyx5wzF",
        "colab_type": "code",
        "outputId": "366c6ff9-15ae-4dcc-ecb8-b2e605b25610",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "X_test = m.test.images\n",
        "print(\"X_test\")\n",
        "print(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_test\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "I2ys8FJzbF8R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Indeed, it looks exactly like the training set images.\n",
        "\n",
        "Let's check its type:"
      ]
    },
    {
      "metadata": {
        "id": "XqtAyjRn5-MA",
        "colab_type": "code",
        "outputId": "502a8ea3-f81b-48bc-90cf-c3543c0b1888",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "kqFfJHVYbW_a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Yup, ```ndarray``` as expected.  What about its shape?"
      ]
    },
    {
      "metadata": {
        "id": "UPfSmlwV6A00",
        "colab_type": "code",
        "outputId": "12eceea0-9be7-40ef-a48f-3f1a741da381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "rfgPmxrcbhT8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have 10000 examples of 784 flattened images.\n",
        "\n",
        "**Note that the ratio between the training and testing subset sizes is quite in favor of training. This could be a problem in a real-world application, but it has been used as default for this particular problem.**\n",
        "\n",
        "Finally, let's check what's in the ```labels``` collection."
      ]
    },
    {
      "metadata": {
        "id": "E1PUfqRp5CUv",
        "colab_type": "code",
        "outputId": "fd2258e5-0472-4ce6-c70c-c7648a69f0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "y_test = m.test.labels\n",
        "print(\"y_test\")\n",
        "print(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_test\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F6ZCg_Cwbz_L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As expected, we have a list of values that should represent the class to which each of the testing example belongs to.\n",
        "\n",
        "Let's confirm that:"
      ]
    },
    {
      "metadata": {
        "id": "TfJhLrBf6Z1X",
        "colab_type": "code",
        "outputId": "f384a2a1-b1d4-4c5a-aaf5-734aaee783c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "bziXEvWn6Q7n",
        "colab_type": "code",
        "outputId": "83a0b86d-d62a-483a-8b15-a8f59efff163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "isic9BvxdDlA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating a classifier with autosklearn"
      ]
    },
    {
      "metadata": {
        "id": "yxJH2DEHdypX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The AutoML approach we're studying here is trying to solve a problem known as **CASH** (*combined algorithm selection and hyperparameter configuration)*.\n",
        "\n",
        "This problem addresses two questions simultaneously: \n",
        "* what is best algorithm for my problem?\n",
        "* how can it be configured to perform best on my problem?\n",
        "\n",
        "Addressing these two questions simultaneously is what lets AutoSklearn create a model that is already configured and is expected to perform well on your input problem.\n",
        "\n",
        "To do that, we must provide a setup for AutoSklearn to run. We do that through arguments of the ```AutoSklearnClassifier``` constructor. \n",
        "\n",
        "Let's see some of the most important:\n",
        "* `time_left_for_this_task`: the total time AutoSklearn will have to create your model. In general, this depends on what algorithms you let AutoSklearn test and how long they take to run on your problem. In general, the total runtime should let AutoSklearn run at least 1000 experiments (trying 1000 different algorithms/configurations).\n",
        "* `per_run_time_limit`: the maximum time a single algorithm/configuration is allowed to run. Again, this depends on what algorithms you let AutoSklearn test and how long they take to run on your problem. In general, you should not allow a single algorithm to use over 1% of your total runtime, but depending on the application this can be relaxed to 10%.\n",
        "* `resampling_strategy`: the strategy used internally by AutoSklearn to separate between training and validation subsets. Holdout is the simplest (and default), but other techniques such as cross validation can also be used.\n",
        "\n",
        "The code below configures an `AutoSklearnClassifier`\n",
        " to have 20min to produce a configured, high-performing algorithm, using holdout as validation strategy and limiting each run to a maximum of 2 min.\n",
        "\n",
        "**Note that the default settings from `AutoSklearnClassifier` will have it run for 1h. This is still not considered enough in practical scenarios -- one should try between 24h and 72h, which mean leaving the computer working for you while you go for a weekend on the beach :D**"
      ]
    },
    {
      "metadata": {
        "id": "K4we7SCk2ljv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "automl_20min = AutoSklearnClassifier(time_left_for_this_task=1200, per_run_time_limit=120, resampling_strategy='holdout')\n",
        "automl = automl_20min"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JWamFuH0RdSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#automl_1h = AutoSklearnClassifier()\n",
        "#automl = automl_1h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHayByPqvIF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We now tell `AutoSklearnClassifier` object to select the configured algorithm that best fits our data:\n",
        "\n",
        "**Beware: this will take as long as you have configured it to take.**"
      ]
    },
    {
      "metadata": {
        "id": "Ba2MFS9s6-Eu",
        "colab_type": "code",
        "outputId": "7203b6d1-bfb2-40a5-8cfa-32a428afc24d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        }
      },
      "cell_type": "code",
      "source": [
        "automl.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2018-10-19 18:04:57,111:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:04:57,150:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:04:59,161:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:01,168:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:03,187:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:05,208:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:07,228:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:09,235:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:11,242:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:13,259:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:15,270:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:17,287:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:19,305:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:21,323:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:23,339:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:25,356:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:27,372:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:29,389:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:31,406:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:33,422:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:35,440:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:37,457:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:39,474:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:41,491:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
            "[WARNING] [2018-10-19 18:05:43,508:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[WARNING] [2018-10-19 18:18:09,091:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
            "[WARNING] [2018-10-19 18:18:09,091:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
            "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
            "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoSklearnClassifier(delete_output_folder_after_terminate=True,\n",
              "           delete_tmp_folder_after_terminate=True,\n",
              "           disable_evaluator_output=False, ensemble_nbest=50,\n",
              "           ensemble_size=50, exclude_estimators=None,\n",
              "           exclude_preprocessors=None, get_smac_object_callback=None,\n",
              "           include_estimators=None, include_preprocessors=None,\n",
              "           initial_configurations_via_metalearning=25,\n",
              "           ml_memory_limit=3072, output_folder=None,\n",
              "           per_run_time_limit=120, resampling_strategy='holdout',\n",
              "           resampling_strategy_arguments=None, seed=1, shared_mode=False,\n",
              "           smac_scenario_args=None, time_left_for_this_task=1200,\n",
              "           tmp_folder=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "ajiZ9hQ4vym9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The object referenced by ```automl``` is "
      ]
    },
    {
      "metadata": {
        "id": "YNfHE4lpwWtA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating the classifier"
      ]
    },
    {
      "metadata": {
        "id": "Jm8fM2Blwk0s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To assess how good the classifier produced by ```AutoSklearnClassifier``` is, we need to have it predict labels for our testing subset:"
      ]
    },
    {
      "metadata": {
        "id": "YrWVAOj46_7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_predicted = automl.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIyV7RQuwxXT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's see what is the output of the `predict` method:"
      ]
    },
    {
      "metadata": {
        "id": "ZDKC3McRG3OF",
        "colab_type": "code",
        "outputId": "0ae44e02-45aa-4b1a-ab19-8bfc7709bf81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"y_predicted\")\n",
        "print(y_predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_predicted\n",
            "[7 2 1 ... 4 5 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-5x3ILvHw4G0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As expected, we get a list of labels predicted for each example. Let's just double-check that: "
      ]
    },
    {
      "metadata": {
        "id": "heQQ9UAoG_AC",
        "colab_type": "code",
        "outputId": "0d1b1d00-dab4-4ec1-e314-e71ceabbf02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "type(y_predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "zHF-cV5sHA9i",
        "colab_type": "code",
        "outputId": "f6a764dc-9a07-4da5-ecd0-f8770b2372f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "y_predicted.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "YCzWwYcBxook",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Yep, we have 10000 predictions in `y_predicted`.\n",
        "\n",
        "Now let's see how do those predictions compare to the true labels we had in `y_test`.\n",
        "\n",
        "We can do that using a **confusion matrix**. \n",
        "\n",
        "If you have m classes in your problem, a confusion matrix is an m-m matrix that counts on its main diagonal the number of times that the prediction was correct.\n",
        "\n",
        "Else, if you have an example from class i mistakenly predicted as belonging to class j, this is reported is cell (i,j):"
      ]
    },
    {
      "metadata": {
        "id": "uCc1IJ7NHEuM",
        "colab_type": "code",
        "outputId": "916988a0-d3a0-4b45-fd41-3a55e2464faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_predicted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 970,    0,    1,    0,    0,    3,    2,    1,    3,    0],\n",
              "       [   0, 1119,    3,    3,    0,    2,    4,    1,    3,    0],\n",
              "       [   5,    0,  999,    6,    2,    1,    3,   10,    6,    0],\n",
              "       [   1,    0,   13,  963,    0,   12,    0,    9,    9,    3],\n",
              "       [   1,    0,    2,    0,  951,    0,    6,    0,    3,   19],\n",
              "       [   5,    1,    1,   14,    4,  853,    7,    1,    5,    1],\n",
              "       [   7,    3,    1,    0,    4,    7,  930,    0,    6,    0],\n",
              "       [   0,    4,   23,    4,    4,    0,    0,  979,    3,   11],\n",
              "       [   4,    0,    7,   12,    7,    9,    4,    4,  918,    9],\n",
              "       [   7,    5,    3,   10,   11,    4,    1,    4,    4,  960]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "bj-uauuVzm6f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Clearly our model is able to classify well most of the examples of the testing set.\n",
        "\n",
        "Let's use an analytical measure to quantify this:"
      ]
    },
    {
      "metadata": {
        "id": "fvU2jHow7DSr",
        "colab_type": "code",
        "outputId": "c5b10f57-e331-42e0-e9c1-ada2c5e19170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"Accuracy score\",accuracy_score(y_test, y_predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score 0.9642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2UHb_Sf42qPd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above result means your classifiers is correct roughly 96.5% of the times you ask it to classify a handwritten digit similar to the ones from the MNIST dataset :D"
      ]
    },
    {
      "metadata": {
        "id": "AZQEtMow4e82",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Critical discussion"
      ]
    },
    {
      "metadata": {
        "id": "EmGbqCVo4jwB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Given the amount of small amount of time we gave to AutoSklearn, results are still pretty good if you have no background at all in computer vision.\n",
        "\n",
        "This is exactly the kind of scenario for which AutoML has been thought: one has little background on machine learning and/or the application problem.\n",
        "\n",
        "However, if you have specialized knowledge, you know that one can get 97% accuracy using an SVM or above 99% using deep learning.\n",
        "\n",
        "Also, setting up AutoSklearnClassifier involves a number of decisions that directly influence the quality of the results, such as the validation strategy.\n",
        "\n",
        "That's why the guys behind the autosklearn package the and AutoML community in general (like me) keep researching this topic -- **feel free to join us :D**"
      ]
    }
  ]
}