{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/leobezerra/automl-pybr14/blob/master/AutoML.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e15U-L9UNTJ1"
   },
   "source": [
    "# AutoML com Python\n",
    "\n",
    "Neste notebook, nós vamos criar um classificador para um problema de classificação de digitos de forma automatizada.\n",
    "\n",
    "Pra isso, nós vamos usar o pacote ```auto-sklearn```, que implementa a abordagem de AutoML chamada AutoSklearn.\n",
    "\n",
    "O AutoSklearn é uma abordagem baseada em comitês (ensembles), que consegue selecionar e configurar algoritmos de forma automatizada.\n",
    "\n",
    "Ele recebe como entrada um conjunto de treino rotulado e produz um algoritmo que espera-se que tenha uma boa performance no problema informado.\n",
    "\n",
    "O AutoSklearn pode ser usado tanto para classificação como para regressão.\n",
    "\n",
    "Neste exemplo, nós vamos criar um classificador para o problema de classificação de digitos escritos à mão conhecido como MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e_Eohh2bOc_e"
   },
   "source": [
    "### Instalando o auto-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FM1i581_OhYL"
   },
   "source": [
    "O pacote ```auto-sklearn``` tem algumas dependências que nós precisamos instalar primeiro:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TYW9fd8lSkLq"
   },
   "source": [
    "**Note que o comando abaixo funciona no Colab e em distribuições Linux baseadas em Debian. Se você usa outra plataforma, você precisará instalar essa biblioteca manualmente.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "id": "hE7eqiD3322e",
    "outputId": "50f4d44e-ea1e-4088-8db7-d0b6c243adc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "build-essential is already the newest version (12.4ubuntu1).\n",
      "Suggested packages:\n",
      "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
      "The following NEW packages will be installed:\n",
      "  swig swig3.0\n",
      "0 upgraded, 2 newly installed, 0 to remove and 12 not upgraded.\n",
      "Need to get 1,100 kB of archives.\n",
      "After this operation, 5,822 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig3.0 amd64 3.0.12-1 [1,094 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 swig amd64 3.0.12-1 [6,460 B]\n",
      "Fetched 1,100 kB in 1s (1,297 kB/s)\n",
      "Selecting previously unselected package swig3.0.\n",
      "(Reading database ... 22278 files and directories currently installed.)\n",
      "Preparing to unpack .../swig3.0_3.0.12-1_amd64.deb ...\n",
      "Unpacking swig3.0 (3.0.12-1) ...\n",
      "Selecting previously unselected package swig.\n",
      "Preparing to unpack .../swig_3.0.12-1_amd64.deb ...\n",
      "Unpacking swig (3.0.12-1) ...\n",
      "Setting up swig3.0 (3.0.12-1) ...\n",
      "Setting up swig (3.0.12-1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install build-essential swig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2468
    },
    "colab_type": "code",
    "id": "7ZT30xys21YS",
    "outputId": "17b1eae7-caa2-4d99-fc40-423a09a34f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "100   209  100   209    0     0   1514      0 --:--:-- --:--:-- --:--:--  1514\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (40.4.3)\n",
      "Collecting nose\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/d8/dd071918c040f50fa1cf80da16423af51ff8ce4a0f2399b7bf8de45ac3d9/nose-1.3.7-py3-none-any.whl (154kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 4.5MB/s \n",
      "\u001b[?25hInstalling collected packages: nose\n",
      "Successfully installed nose-1.3.7\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
      "Collecting Cython\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/3f/cac281f3f019b825bbc03fa8cb7eb03d9c355f4aa9eef978279a4966cb21/Cython-0.29-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.1MB 9.4MB/s \n",
      "\u001b[?25hInstalling collected packages: Cython\n",
      "Successfully installed Cython-0.29\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (1.14.6)\n",
      "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (0.19.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.14.1) (1.14.6)\n",
      "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (0.19.2)\n",
      "Collecting xgboost==0.7.post3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/1c/a2ec1798d444e2b86b27fdbf18d9ab08c25c3d374de77429b55a76f42404/xgboost-0.7.post3.tar.gz (450kB)\n",
      "\u001b[K    100% |████████████████████████████████| 460kB 5.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost==0.7.post3) (1.14.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost==0.7.post3) (0.19.1)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Running setup.py bdist_wheel for xgboost ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/94/02/70/61da39c3c6e67d052eb5c618c2b5188adcd6ab0128025f1323\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "  Found existing installation: xgboost 0.7.post4\n",
      "    Uninstalling xgboost-0.7.post4:\n",
      "      Successfully uninstalled xgboost-0.7.post4\n",
      "Successfully installed xgboost-0.7.post3\n",
      "Collecting lockfile\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/22/9460e311f340cb62d26a38c419b1381b8593b0bb6b5d1f056938b086d362/lockfile-0.12.2-py2.py3-none-any.whl\n",
      "Installing collected packages: lockfile\n",
      "Successfully installed lockfile-0.12.2\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (0.12.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.7)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n",
      "Collecting liac-arff\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/c3/6966861e2f4d302ac3a36821f7ac503b57d98cb9cc3b28e9cd8ef8b7df65/liac-arff-2.3.1.tar.gz\n",
      "Building wheels for collected packages: liac-arff\n",
      "  Running setup.py bdist_wheel for liac-arff ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/f0/15/97687f0a23a6859a7ced7e09271d321930c6641c2675d04745\n",
      "Successfully built liac-arff\n",
      "Installing collected packages: liac-arff\n",
      "Successfully installed liac-arff-2.3.1\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.6)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
      "Collecting ConfigSpace<0.5,>=0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/53/e54835d444153ba461fe8aec28533a1ffc3c5531b89509c8029b6b57a7e7/ConfigSpace-0.4.7.tar.gz (913kB)\n",
      "\u001b[K    100% |████████████████████████████████| 921kB 19.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (1.14.6)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (2.2.2)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (3.6.6)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0) (0.29)\n",
      "Building wheels for collected packages: ConfigSpace\n",
      "  Running setup.py bdist_wheel for ConfigSpace ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fb/05/bc/ace7b3602c315c402176a9280296a59275aa826476517faa24\n",
      "Successfully built ConfigSpace\n",
      "Installing collected packages: ConfigSpace\n",
      "Successfully installed ConfigSpace-0.4.7\n",
      "Collecting pynisher>=0.4\n",
      "  Downloading https://files.pythonhosted.org/packages/b2/21/c86c64c305da6d43fb89780d33cbc839c07736b71955a8bdb642a02b7538/pynisher-0.5.0.tar.gz\n",
      "Collecting docutils>=0.3 (from pynisher>=0.4)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 5.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4) (40.4.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4) (5.4.7)\n",
      "Building wheels for collected packages: pynisher\n",
      "  Running setup.py bdist_wheel for pynisher ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/af/2a/c4/ec3abc8a2f786ef9786ea8fe6ff629a4e54812a3f98cc41b47\n",
      "Successfully built pynisher\n",
      "Installing collected packages: docutils, pynisher\n",
      "Successfully installed docutils-0.14 pynisher-0.5.0\n",
      "Collecting pyrfr<0.8,>=0.7\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/c6/c555cfa3c7d0078dded091d4901ed52344bbb925077aa70b871faf35fd58/pyrfr-0.7.4.tar.gz (291kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 4.6MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyrfr\n",
      "  Running setup.py bdist_wheel for pyrfr ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/fb/98/fd/b1d53cab6d5ed836980777d9733d7e549d82a727650eed6f6d\n",
      "Successfully built pyrfr\n",
      "Installing collected packages: pyrfr\n",
      "Successfully installed pyrfr-0.7.4\n",
      "Collecting smac\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/ab/2b0a6fb00bd76e2415a04dcca453ad0b0db9b4218b02401306ff2bc6135d/smac-0.8.0.tar.gz (94kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 2.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from smac) (40.4.3)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from smac) (0.29)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from smac) (1.14.6)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from smac) (0.19.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from smac) (1.11.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from smac) (5.4.7)\n",
      "Requirement already satisfied: pynisher>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from smac) (0.5.0)\n",
      "Requirement already satisfied: ConfigSpace<0.5,>=0.4.3 in /usr/local/lib/python3.6/dist-packages (from smac) (0.4.7)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from smac) (0.19.2)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from smac) (3.6.6)\n",
      "Requirement already satisfied: pyrfr>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from smac) (0.7.4)\n",
      "Collecting sphinx (from smac)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/e0/e9e83b244eaa382ba21896dda6172617e47aff0be225eb72782cca105d3c/Sphinx-1.8.1-py2.py3-none-any.whl (3.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.1MB 7.3MB/s \n",
      "\u001b[?25hCollecting sphinx_rtd_theme (from smac)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/0c/e4a462190506bc4bff6ca8cf93da07b2d13e540466d2e8a760352d0c69b0/sphinx_rtd_theme-0.4.2-py2.py3-none-any.whl (6.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.4MB 5.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from smac) (0.12.5)\n",
      "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher>=0.4.1->smac) (0.14)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.3->smac) (2.2.2)\n",
      "Collecting imagesize (from sphinx->smac)\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/b6/aef66b4c52a6ad6ac18cf6ebc5731ed06d8c9ae4d3b2d9951f261150be67/imagesize-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.18.4)\n",
      "Collecting snowballstemmer>=1.1 (from sphinx->smac)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/6c/8a935e2c7b54a37714656d753e4187ee0631988184ed50c0cf6476858566/snowballstemmer-1.2.1-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 24.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.1.3)\n",
      "Collecting alabaster<0.8,>=0.7 (from sphinx->smac)\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ad/00b090d23a222943eb0eda509720a404f531a439e803f6538f35136cae9e/alabaster-0.7.12-py2.py3-none-any.whl\n",
      "Collecting babel!=2.0,>=1.3 (from sphinx->smac)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ad/c6f60602d3ee3d92fbed87675b6fb6a6f9a38c223343ababdb44ba201f10/Babel-2.6.0-py2.py3-none-any.whl (8.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.1MB 4.8MB/s \n",
      "\u001b[?25hCollecting sphinxcontrib-websupport (from sphinx->smac)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/69/3c2fbdc3702358c5b34ee25e387b24838597ef099761fc9a42c166796e8f/sphinxcontrib_websupport-1.1.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac) (2.10)\n",
      "Collecting packaging (from sphinx->smac)\n",
      "  Downloading https://files.pythonhosted.org/packages/89/d1/92e6df2e503a69df9faab187c684585f0136662c12bb1f36901d426f3fab/packaging-18.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (2018.10.15)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac) (3.0.4)\n",
      "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel!=2.0,>=1.3->sphinx->smac) (2018.5)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac) (1.0)\n",
      "Building wheels for collected packages: smac\n",
      "  Running setup.py bdist_wheel for smac ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/12/52/83/d2d66a840968025d072ddb1cd776fdc5eb5e337e1cc887bc3f\n",
      "Successfully built smac\n",
      "Installing collected packages: imagesize, snowballstemmer, alabaster, babel, sphinxcontrib-websupport, packaging, sphinx, sphinx-rtd-theme, smac\n",
      "Successfully installed alabaster-0.7.12 babel-2.6.0 imagesize-1.1.0 packaging-18.0 smac-0.8.0 snowballstemmer-1.2.1 sphinx-1.8.1 sphinx-rtd-theme-0.4.2 sphinxcontrib-websupport-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs -n 1 -L 1 pip install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VpHBKBGOhUg"
   },
   "source": [
    "**Note que o pip espera o nome ```auto-sklearn``` em vez de ```autosklearn```**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "oY2e7h5F2ry4",
    "outputId": "5d09eeba-97ad-4038-b69a-64691b98e974"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting auto-sklearn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/a6/cbbff9205cb7dc71d67a6c05ecdd5aa05856bc1638360238d25a4a01d670/auto-sklearn-0.4.0.tar.gz (3.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.4MB 9.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (40.4.3)\n",
      "Requirement already satisfied: nose in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.3.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.11.0)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.29)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (1.14.6)\n",
      "Requirement already satisfied: scipy>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.1)\n",
      "Requirement already satisfied: scikit-learn<0.20,>=0.19 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.19.2)\n",
      "Requirement already satisfied: lockfile in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.12.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (5.4.7)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (3.13)\n",
      "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (2.3.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.22.0)\n",
      "Requirement already satisfied: ConfigSpace<0.5,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.4.7)\n",
      "Collecting pynisher<0.5,>=0.4 (from auto-sklearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/cd/4e0469a55fd280df177af2d5e94d72541d3bb0115280e31a23c8922987e6/pynisher-0.4.2.tar.gz\n",
      "Requirement already satisfied: pyrfr<0.8,>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.4)\n",
      "Requirement already satisfied: smac<0.9,>=0.8 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.8.0)\n",
      "Requirement already satisfied: xgboost==0.7.post3 in /usr/local/lib/python3.6/dist-packages (from auto-sklearn) (0.7.post3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2018.5)\n",
      "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->auto-sklearn) (2.5.3)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (2.2.2)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from ConfigSpace<0.5,>=0.4.0->auto-sklearn) (3.6.6)\n",
      "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.6/dist-packages (from pynisher<0.5,>=0.4->auto-sklearn) (0.14)\n",
      "Requirement already satisfied: sphinx in /usr/local/lib/python3.6/dist-packages (from smac<0.9,>=0.8->auto-sklearn) (1.8.1)\n",
      "Requirement already satisfied: sphinx-rtd-theme in /usr/local/lib/python3.6/dist-packages (from smac<0.9,>=0.8->auto-sklearn) (0.4.2)\n",
      "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.18.4)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (0.7.12)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (1.1.0)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.6.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (1.2.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (18.0)\n",
      "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (2.10)\n",
      "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx->smac<0.9,>=0.8->auto-sklearn) (1.1.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx->smac<0.9,>=0.8->auto-sklearn) (2018.10.15)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->sphinx->smac<0.9,>=0.8->auto-sklearn) (1.0)\n",
      "Building wheels for collected packages: auto-sklearn, pynisher\n",
      "  Running setup.py bdist_wheel for auto-sklearn ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3f/4e/d9/489ca4cb2f6fd94f58180b0073d15746583f772f25d9178b94\n",
      "  Running setup.py bdist_wheel for pynisher ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/35/cb/37fe9c279ac6e56fc8805e146a431c27550dce1ad868ffa04e\n",
      "Successfully built auto-sklearn pynisher\n",
      "Installing collected packages: pynisher, auto-sklearn\n",
      "  Found existing installation: pynisher 0.5.0\n",
      "    Uninstalling pynisher-0.5.0:\n",
      "      Successfully uninstalled pynisher-0.5.0\n",
      "Successfully installed auto-sklearn-0.4.0 pynisher-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install auto-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F82AQt_0Q9kK"
   },
   "source": [
    "## Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KlRSVHzSTMNs"
   },
   "source": [
    "Para este exemplo, nós vamos usar o módulo de classificação do AutoSklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQEOA3r0TJLi"
   },
   "outputs": [],
   "source": [
    "from autosklearn.classification import AutoSklearnClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AW80nPVREcg"
   },
   "source": [
    "Nós também vamos precisar do módulo `metrics` do `scikit-learn` ao avaliar o modelo produzido. Nós vamos usar as ferramentas de acurácia e matriz de confusão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1TfvL1K2PCr"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wi3AiCGwTigl"
   },
   "source": [
    "## Lendo os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QRTDnfy_TRg0"
   },
   "source": [
    "Nós vamos usar o dataset MNIST disponível no TensorFlow.\n",
    "\n",
    "**Você também pode baixar este dataset de outras fontes, caso você não tenha (ou não queira ter) o TensorFlow no seu computador.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2k4rjulgTRXA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "pHssKO0b42Tp",
    "outputId": "6bf194b9-cdeb-470a-981a-e469700d62dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [18:04:29:tensorflow] From <ipython-input-7-d32cef2642e0>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "[WARNING] [18:04:29:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "[WARNING] [18:04:29:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "[WARNING] [18:04:30:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [18:04:30:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "[WARNING] [18:04:30:tensorflow] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "m=input_data.read_data_sets(\"MNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "huj7FcvTT07d"
   },
   "source": [
    "Este dataset vem previamente dividido em subconjuntos de treine e de teste.\n",
    "\n",
    "**Isto é extremamente importante para garantir que o modelo produzido seja bom em classificar novas amostras e não só as que ele já conhece.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rh7WxAnDURry"
   },
   "source": [
    "### Exemplos de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMgNQ6-wUiDV"
   },
   "source": [
    "O subconjunto de treino contém duas coleções: ```images``` e  ```labels```.\n",
    "\n",
    "Vamos verificar o que ```images``` contém:\n",
    "\n",
    "**A comunidade de aprendizado de máquina convencionou o uso de X para exemplos e y para rótulos.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "hEbqD3uW47da",
    "outputId": "52406684-1a3f-4eb3-c6ca-604a45cd5179"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_train = m.train.images\n",
    "print(\"X_train\")\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Kmgrh_jU_Hj"
   },
   "source": [
    "Pelo que conseguimos ver, `X_train` é uma matriz com muitos zeros.\n",
    "\n",
    "Vamos fuçar um pouco mais:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KUPo2LUt5XMm",
    "outputId": "43658618-e166-43eb-a40e-186566e70b88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jTjuNeKPWkRl"
   },
   "source": [
    "Se você está acostumado com `pandas`, `scikit-learn` ou outros pacotes de ciência de dados / aprendizado de máquina, você provavelemente já se deparou com um `ndarray` do pacote `numpy`.\n",
    "\n",
    "Basicamente, é uma forma mais eficiente da `list` do Python. Nós podemos verificar suas dimensões usando o atributo `shape `:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xHJl7kXg5Haz",
    "outputId": "3d8e8985-288c-4d18-de74-891d0c81f3f0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2F6klrpCXaOg"
   },
   "source": [
    "A forma da coleção ```images``` revela que ele contém 55000 imagens, cada uma representada por uma lista de 784 valores.\n",
    "\n",
    "Cada vetor é o resultado da linearização da imagem original, que contém 28x28 pixels (28 * 28 = 784).\n",
    "\n",
    "**Esta representação costumava ser bastante comum em problemas de visão computacional antes do surgimento de algoritmos de deep learning. Apesar de ser compatível com vários algoritmos clássicos, esta representação perde a relação espacial vertical entre os pixels.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mjAsvMXAYTCs"
   },
   "source": [
    "Agora vamos ver o que há na coleção ```labels```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "sH8LF_KX5Bd6",
    "outputId": "522176d3-2832-4969-b3fc-e311590bfb43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train\n",
      "[7 3 4 ... 5 6 8]\n"
     ]
    }
   ],
   "source": [
    "y_train = m.train.labels\n",
    "print(\"y_train\")\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KrinBiaWYZJu"
   },
   "source": [
    "Desta vez temos um `ndarray` unidimensional, mas o que esses valores significam?\n",
    "\n",
    "Vamos verificar seu tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4cALLzfI5iEz",
    "outputId": "21b58b03-df32-4a2b-ea45-460b04aeb1ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDtZ4QGzY5jc"
   },
   "source": [
    "Mais uma vez temos um ```ndarray```,  então podemos ver sua forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "qBeQN0jh5rCc",
    "outputId": "75835743-2f0c-4076-b8ed-d0960a285908"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000,)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZJl8ux4rY-5z"
   },
   "source": [
    "A coleção ```labels``` informa a qual classe cada uma das 55000 imagens da coleção ```images``` pertence.\n",
    "\n",
    "Neste caso, rótulos variam de 0 to 9, uma vez que são esses os dígitos escritos a mão presentes no dataset.\n",
    "\n",
    "**Nós podemos fazer um pouco de análise descritiva dos nossos dados usando Pandas e bibliotecas de plot. Aqui nós vamos fazer algo simples e verificar apenas a distribuição dos exemplos de treino entre as diferentes classes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "VfP9Gbi8ZeL2",
    "outputId": "9662bd70-6db5-4470-981a-1b52a413d0d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6179\n",
       "7    5715\n",
       "3    5638\n",
       "2    5470\n",
       "9    5454\n",
       "0    5444\n",
       "6    5417\n",
       "8    5389\n",
       "4    5307\n",
       "5    4987\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import Series\n",
    "Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGOrOSf6Z7EA"
   },
   "source": [
    "Note que o dataaset contém muito mais imagens do número 1 do que número 5.\n",
    "\n",
    "**É possível preprocessar os dados para balancear o número de exemplos de cada classe. Aqui eu não vou fazer isso pra manter o notebook simples, mas em geral isto é útil para a performance dos modelos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "otcqEQZTaUda"
   },
   "source": [
    "### Exemplos de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LvwtbsIZahwM"
   },
   "source": [
    "Agora vamos checar como é o subconjunto de teste. Novamente, ele contém coleções `images` e `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "N1t3Cvyx5wzF",
    "outputId": "366c6ff9-15ae-4dcc-ecb8-b2e605b25610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_test = m.test.images\n",
    "print(\"X_test\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I2ys8FJzbF8R"
   },
   "source": [
    "De fato, parece exatamente com o conjunto de imagens de treino.\n",
    "\n",
    "Vamos checar seu tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XqtAyjRn5-MA",
    "outputId": "502a8ea3-f81b-48bc-90cf-c3543c0b1888"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kqFfJHVYbW_a"
   },
   "source": [
    "É, ```ndarray``` como esperado. E sua forma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UPfSmlwV6A00",
    "outputId": "12eceea0-9be7-40ef-a48f-3f1a741da381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rfgPmxrcbhT8"
   },
   "source": [
    "Agora nós temos 10000 exemplos de imagens 28x28 linearizadas.\n",
    "\n",
    "**Note que a proporção entre os subconjuntos de treino e teste é bastante a favor do treino. Isto poderia ser um problema em uma aplicação real, mas tem sido usado como padrão para este problema em particular.**\n",
    "\n",
    "Por último, vamos ver o que tem na coleção `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "E1PUfqRp5CUv",
    "outputId": "fd2258e5-0472-4ce6-c70c-c7648a69f0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "y_test = m.test.labels\n",
    "print(\"y_test\")\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6ZCg_Cwbz_L"
   },
   "source": [
    "Como esperado, temos uma lista de valores que representam a classe à qual cada exemplo de teste pertence.\n",
    "\n",
    "Vamos confirmar isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TfJhLrBf6Z1X",
    "outputId": "f384a2a1-b1d4-4c5a-aaf5-734aaee783c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bziXEvWn6Q7n",
    "outputId": "83a0b86d-d62a-483a-8b15-a8f59efff163"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isic9BvxdDlA"
   },
   "source": [
    "## Criando um classificador com o pacote `autosklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yxJH2DEHdypX"
   },
   "source": [
    "A abordagem AutoML que estamos estudando aqui está tentando resolver um problema conhecido como **CASH** (seleção e configuração de hiperparâmetros combinada de algoritmos, do inglês *combined algorithm selection and hyperparameter configuration*). \n",
    "\n",
    "Este problema lida com duas questões ao mesmo tempo:\n",
    "* qual o melhor algoritmo para o meu problema?\n",
    "* como ele pode ser configurado para apresentar a melhor performance possível no meu problema?\n",
    "\n",
    "Lidar com essas duas questões ao mesmo tempo é o que permite que o AutoSklearn identifique um modelo que já é configurado e que se espera que tenha uma boa performance no problema de entrada.\n",
    "\n",
    "Para isso, nós precisamos fornecer um setup para o AutoSklearn rodar. Nós fazemos isso através dos parâmetros do construtor da classe `AutoSklearnClassifier`. \n",
    "\n",
    "Vamos ver alguns dos mais importantes:\n",
    "* `time_left_for_this_task`: o tempo total que o AutoSklearn terá pra selecionar/configurar algoritmos. Em geral, isso depende de quais algoritmos você permite que o AutoSklearn teste e de quando tempo eles levam pra rodar no seu problema. Na prática, o tempo total deve permitir que o AutoSklearn rode pelo menos 1000 experiments (testar 1000 algoritmos/configurações diferentes).\n",
    "* `per_run_time_limit`: o tempo máximo que um único algoritmo/configuração pode usar. Novamente, isto depende de quais algoritmos você permite que o AutoSklearn teste e de quando tempo eles levam pra rodar no seu problema. Em geral, você não deve permitir que um único algoritmo/configuração use mais de 1% do seu tempo total de execução, mas dependendo da aplicação esse limite pode ser flexibilizado para 10%.\n",
    "* `resampling_strategy`: a estratégia usada internamente pelo AutoSklearn para separa entre subconjuntos de treino e validação. Holdout é a mais simples (e a padrão), mas outras técnicas como validação cruzada também podem ser usadas.\n",
    "\n",
    "O código abaixo configura um `AutoSklearnClassifier` para ter 20min para selecionar/configurar um algoritmo de alta performance, usando holdout como estratégia de validação e limitando cada teste para um máximo de 2 min.\n",
    "\n",
    "**Note que as configurações padrões do construtor `AutoSklearnClassifier` permitem que o AutoSklearn rode por 1h. Isto ainda não é considerado suficiente em cenários práticos -- você deveria tentar algo entre 24h e e 72h, o que significa deixar o computador trabalhando pra você enquanto você vai passar o fim de semana na praia :D**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4we7SCk2ljv"
   },
   "outputs": [],
   "source": [
    "automl_20min = AutoSklearnClassifier(time_left_for_this_task=1200, per_run_time_limit=120, resampling_strategy='holdout')\n",
    "automl = automl_20min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JWamFuH0RdSs"
   },
   "outputs": [],
   "source": [
    "#automl_1h = AutoSklearnClassifier()\n",
    "#automl = automl_1h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHayByPqvIF5"
   },
   "source": [
    "Agora nós dizemos para o objeto `AutoSklearnClassifier` para selecionar o algoritmo configurado que melhor consiga modelar nossos dados:\n",
    "\n",
    "**Cuidado: o código a seguir vai levar o tempo que você tiver configurado para levar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 923
    },
    "colab_type": "code",
    "id": "Ba2MFS9s6-Eu",
    "outputId": "7203b6d1-bfb2-40a5-8cfa-32a428afc24d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2018-10-19 18:04:57,111:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:04:57,150:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:04:59,161:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:01,168:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:03,187:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:05,208:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:07,228:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:09,235:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:11,242:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:13,259:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:15,270:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:17,287:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:19,305:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:21,323:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:23,339:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:25,356:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:27,372:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:29,389:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:31,406:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:33,422:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:35,440:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:37,457:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:39,474:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:41,491:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n",
      "[WARNING] [2018-10-19 18:05:43,508:EnsembleBuilder(1):892b6daec9844b8aceec8dd30f96b266] No models better than random - using Dummy Classifier!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2018-10-19 18:18:09,091:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n",
      "[WARNING] [2018-10-19 18:18:09,091:smac.intensification.intensification.Intensifier] Challenger was the same as the current incumbent; Skipping challenger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n",
      "/usr/local/lib/python3.6/dist-packages/autosklearn/evaluation/train_evaluator.py:197: RuntimeWarning: Mean of empty slice\n",
      "  Y_train_pred = np.nanmean(Y_train_pred_full, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoSklearnClassifier(delete_output_folder_after_terminate=True,\n",
       "           delete_tmp_folder_after_terminate=True,\n",
       "           disable_evaluator_output=False, ensemble_nbest=50,\n",
       "           ensemble_size=50, exclude_estimators=None,\n",
       "           exclude_preprocessors=None, get_smac_object_callback=None,\n",
       "           include_estimators=None, include_preprocessors=None,\n",
       "           initial_configurations_via_metalearning=25,\n",
       "           ml_memory_limit=3072, output_folder=None,\n",
       "           per_run_time_limit=120, resampling_strategy='holdout',\n",
       "           resampling_strategy_arguments=None, seed=1, shared_mode=False,\n",
       "           smac_scenario_args=None, time_left_for_this_task=1200,\n",
       "           tmp_folder=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ajiZ9hQ4vym9"
   },
   "source": [
    "**O objeto referenciado por ```automl``` é um algoritmo configurado e esta classe oferece diferentes métodos. Dê uma olhada na [API do AutoSklearn](http://automl.github.io/auto-sklearn/stable/api.html) :D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YNfHE4lpwWtA"
   },
   "source": [
    "## Avaliando o classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jm8fM2Blwk0s"
   },
   "source": [
    "Para avaliar quão bom o classificador produzido pelo `AutoSklearnClassifier` é, nós precisamos que usá-lo para predizer rótulos para o subconjunto de teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YrWVAOj46_7r"
   },
   "outputs": [],
   "source": [
    "y_predicted = automl.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIyV7RQuwxXT"
   },
   "source": [
    "Vamos ver qual é a saída do método `predict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ZDKC3McRG3OF",
    "outputId": "0ae44e02-45aa-4b1a-ab19-8bfc7709bf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_predicted\n",
      "[7 2 1 ... 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_predicted\")\n",
    "print(y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5x3ILvHw4G0"
   },
   "source": [
    "Como esperado, nós recebemos uma lista de rótulos preditos para cada exemplo. Vamos só confirmar isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "heQQ9UAoG_AC",
    "outputId": "0d1b1d00-dab4-4ec1-e314-e71ceabbf02d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zHF-cV5sHA9i",
    "outputId": "f6a764dc-9a07-4da5-ecd0-f8770b2372f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCzWwYcBxook"
   },
   "source": [
    "É, nós temos 10000 predições em `y_predicted`.\n",
    "\n",
    "Agora vamos comparar essas predições com os rótulos reais que nós tínhamos em `y_test`.\n",
    "\n",
    "Nós podemos fazer isso usando uma **matriz de confusão**.\n",
    "\n",
    "Se você tem m classes no seu problema, uma matriz de confusão é uma matriz mxm\n",
    "If you have m classes in your problem, a confusion matrix is an m x m que conta na sua matriz diagonal o número de vezes que a predição estava correta.\n",
    "\n",
    "Caso contrário, se você tiver um exemplo da classe i predito erroneamente como sendo da classe j, isso é informado na célula (i,j):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "uCc1IJ7NHEuM",
    "outputId": "916988a0-d3a0-4b45-fd41-3a55e2464faa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 970,    0,    1,    0,    0,    3,    2,    1,    3,    0],\n",
       "       [   0, 1119,    3,    3,    0,    2,    4,    1,    3,    0],\n",
       "       [   5,    0,  999,    6,    2,    1,    3,   10,    6,    0],\n",
       "       [   1,    0,   13,  963,    0,   12,    0,    9,    9,    3],\n",
       "       [   1,    0,    2,    0,  951,    0,    6,    0,    3,   19],\n",
       "       [   5,    1,    1,   14,    4,  853,    7,    1,    5,    1],\n",
       "       [   7,    3,    1,    0,    4,    7,  930,    0,    6,    0],\n",
       "       [   0,    4,   23,    4,    4,    0,    0,  979,    3,   11],\n",
       "       [   4,    0,    7,   12,    7,    9,    4,    4,  918,    9],\n",
       "       [   7,    5,    3,   10,   11,    4,    1,    4,    4,  960]])"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bj-uauuVzm6f"
   },
   "source": [
    "Claramente, nosso modelo consegue classificar bem a maior parte dos exemplos do subconjunto de testes.\n",
    "\n",
    "Vamos usar uma medida analítica para quantificar isso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fvU2jHow7DSr",
    "outputId": "c5b10f57-e331-42e0-e9c1-ada2c5e19170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.9642\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\",accuracy_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2UHb_Sf42qPd"
   },
   "source": [
    "O resultado acima significa que seus classificador está correto em aproximadamente 96,5% das vezes que você pede para ele classificar um dígito escrito a mão similar aos que existem no dataset MNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AZQEtMow4e82"
   },
   "source": [
    "## Critical discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EmGbqCVo4jwB"
   },
   "source": [
    "Dada a pequena quantidade de tempo que nós demos ao AutoSklearn, os resultados ainda são muito bons se você não tem nenhum tipo de background em visão computacional.\n",
    "\n",
    "Este é exatamente o tipo de cenário pro qual AutoML foi pensado: alguém que tem pouco background em aprendizado de máquina e/ou na aplicação.\n",
    "\n",
    "No entanto, se você tiver conhecimento especializado, você sabe que é possível obter uma acurácia de 97% usando SVM e de mais de 99% usando deep learning.\n",
    "\n",
    "Além disso, configurar o `AutoSklearnClassifier` ennvolves a number of decisions that directly influence the quality of the results, such as the validation strategy.\n",
    "\n",
    "That's why the guys behind the autosklearn package the and AutoML community in general (like me) keep researching this topic -- **feel free to join us :D**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copy of AutoML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
